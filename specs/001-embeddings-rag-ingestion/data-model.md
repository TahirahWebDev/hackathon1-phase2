# Data Model: RAG Content Ingestion Pipeline

## Overview
This document defines the key data entities for the RAG content ingestion pipeline, based on the feature specification requirements.

## Entity: Document Chunk
**Description**: A segment of documentation content that has been cleaned and prepared for embedding.

**Attributes**:
- `id` (string): Unique identifier for the chunk
- `content` (string): The text content of the chunk
- `source_url` (string): The URL where this content originated
- `section_title` (string): The title of the section this chunk belongs to
- `metadata` (dict): Additional metadata associated with the chunk
- `created_at` (datetime): Timestamp when the chunk was created

**Relationships**:
- Associated with one `Embedding Vector`
- Belongs to one source document/page

## Entity: Embedding Vector
**Description**: A numerical representation of a document chunk generated by Cohere models.

**Attributes**:
- `id` (string): Unique identifier for the embedding
- `vector` (list[float]): The embedding vector values
- `document_chunk_id` (string): Reference to the source document chunk
- `metadata` (dict): Additional metadata including source_url, section_title
- `created_at` (datetime): Timestamp when the embedding was created

**Relationships**:
- Associated with one `Document Chunk`
- Stored in Qdrant vector database

## Entity: Crawled Page
**Description**: The raw content extracted from a Docusaurus URL.

**Attributes**:
- `id` (string): Unique identifier for the crawled page
- `url` (string): The URL that was crawled
- `raw_content` (string): The raw HTML content from the page
- `clean_content` (string): The cleaned text content extracted from the page
- `title` (string): The title of the page
- `status_code` (int): HTTP status code of the crawl request
- `crawled_at` (datetime): Timestamp when the page was crawled
- `error_message` (string, optional): Error message if crawling failed

**Relationships**:
- Contains multiple `Document Chunk` entities after processing
- May generate multiple `Document Chunk` entities after chunking

## Entity: Ingestion Job
**Description**: A tracking entity for a complete ingestion pipeline run.

**Attributes**:
- `id` (string): Unique identifier for the ingestion job
- `source_urls` (list[string]): List of URLs to be ingested
- `status` (string): Current status (e.g., "pending", "in_progress", "completed", "failed")
- `started_at` (datetime): Timestamp when the job started
- `completed_at` (datetime, optional): Timestamp when the job completed
- `total_pages_crawled` (int): Number of pages successfully crawled
- `total_chunks_created` (int): Number of chunks created
- `total_embeddings_stored` (int): Number of embeddings stored in vector DB
- `error_count` (int): Number of errors encountered during the job

**Relationships**:
- Contains multiple `Crawled Page` entities
- Associated with multiple `Document Chunk` entities
- Associated with multiple `Embedding Vector` entities

## Validation Rules

### Document Chunk Validation
- Content must not be empty
- Content length must be within specified limits (min 10 tokens, max 1024 tokens)
- Source URL must be a valid URL format
- ID must be unique

### Embedding Vector Validation
- Vector must have the correct dimensionality for the chosen model
- Document chunk ID must reference an existing document chunk
- ID must be unique

### Crawled Page Validation
- URL must be a valid URL format
- Status code must be 200 for successful crawls
- Raw content must not be empty for successful crawls
- ID must be unique

### Ingestion Job Validation
- Source URLs list must not be empty
- Status must be one of the allowed values
- ID must be unique